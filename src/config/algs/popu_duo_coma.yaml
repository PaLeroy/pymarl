# --- population specific parameters ---
# --- This config file uses the episodic runner, which is useful for testing locally ---

# Global parameter, indep of agent type
runner_function: "population"
runner: "parallel_runner_population"
batch_size_run: 8 # Number of env at the same time

name: "population_duo_coma"

use_cuda: False

matchmaking: "duo"

save_model_interval: 20000
save_model: True # Save the models to disk

use_tensorboard: True

n_agent_type: 1

log_interval: 2000
runner_log_interval: 2000
learner_log_interval: 2000
agent_type_1:
    number: 2
    mac: "basic_mac"
    action_selector: "multinomial"
    epsilon_start: .5
    epsilon_finish: .01
    epsilon_anneal_time: 100000
    mask_before_softmax: False

    gamma: 0.99

    buffer_size: 8

    # update the target network every {} training steps
    target_update_interval: 200

    lr: 0.0005
    critic_lr: 0.0005
    td_lambda: 0.8

    # use COMA
    agent_output_type: "pi_logits"
    learner: "coma_learner"
    critic_q_fn: "coma"
    critic_baseline_fn: "coma"
    critic_train_mode: "seq"
    critic_train_reps: 1
    q_nstep: 0  # 0 corresponds to default Q, 1 is r + gamma*Q, etc

    learner_log_interval: 2000 # Log training stats every {} timesteps


    # --- RL hyperparameters ---
    batch_size: 8 # Number of episodes to train on
    optim_alpha: 0.99 # RMSProp alpha
    optim_eps: 0.00001 # RMSProp epsilon
    grad_norm_clip: 10 # Reduce magnitude of gradients above this L2 norm

    # --- Agent parameters ---
    agent: "rnn" # Default rnn agent
    rnn_hidden_dim: 64 # Size of hidden state for default rnn agent
    obs_agent_id: True # Include the agent's one_hot id in the observation
    obs_last_action: True # Include the agent's last action (one_hot) in the observation

    # --- Logging options ---
    save_model: [True, True] # Save the models to disk
    save_model_interval: [200000, 200000] # Save models after this many timesteps
    checkpoint_path: ["", ""] # Load a checkpoint from this path
    load_step: [0, 0] # Load model trained on this many timesteps (0 if choose max possible)

